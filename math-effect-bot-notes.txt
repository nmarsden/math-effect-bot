----------------------------
--- Original source code ---
----------------------------
Math Effect source code on github
- https://github.com/ilfate/laravel.ilfate.net

-----------
--- DOM ---
-----------
DOM for player and one button
-----------------------------
<div class="unit-1 playerUnit">
  <div class="tdButton fa-arrow-circle-down"></div>
</div>

DOM for final modal dialog
--------------------------
<div id="myModal"
    <div id="turnsSurvived">10</div>
    <div id="unitsKilled">2</div>
    <div id="pointsEarned">16</div>

     <a class="btn">Restart</a>
</div>
	 
---------------------
--- Code Snippets ---
---------------------
Click first player button found
-------------------------------
$(".tdButton:visible").first().click()

Output final result
-------------------
console.log("[turns: " + $("#turnsSurvived").text() + "][kills: " + $("#unitsKilled").text() + "][points: " + $("#pointsEarned").text() + "]");

// [turns: 5][kills: 2][points: 3]

AutoPlay game forever
---------------------
var autoPlay = function () {
    if ($("#myModal:visible").size() == 0) {
        $(".tdButton:visible").first().click();
		setTimeout(autoPlay, 1000);
    } else {
        console.log("[turns: " + $("#turnsSurvived").text() + "][kills: " + $("#unitsKilled").text() + "][points: " + $("#pointsEarned").text() + "]");
		
		window.location = "http://ilfate.net/MathEffect"
		setTimeout(autoPlay, 3000);
	}
}

setTimeout(autoPlay, 1000);

-----------------------
--- Q-Learner Notes ---
-----------------------

ConvnetJS - Reinforcement Learning Example
------------------------------------------
http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html

Questions
- What actions should be rewarded/punished?
  a) +5 : reward for killing an enemy. a higher reward for the fewer turns the enemy bot has taken (an even higher reward for killing a 'boss' bot)
  b) +3 : reward for collecting bonus points
  c) +1 : reward for increasing player power
  c) -3 : punish for collecting negative points
  d) -6 : punish for letting the enemy capture the base
  e) -6 : punish for invalid action (eg. choosing invalid direction for player; moving player that does not exist;)
  f) -3 : punish for player not moving and on the edge of the board
  g) maybe reward for moving towards enemy?
  h) maybe punish for moving away from enemy?

- What should be the inputs?
  a) 81 (9 x 9) inputs for board state with values...
     - 0 = empty square
     - 1-5 = player state (1=player not moving, 2=player moving up, 3=player moving right, 4=player moving down, 5=player moving left)
     - 6-10 = enemy state (0=enemy with moving direction unknown, 1=enemy moving up, 2=enemy moving right, 3=enemy moving down, 4=enemy moving left)
     - 11 = increase power square
     - 12 = decrease power square

     where board states are ordered from left to right, top to bottom on the board

- What should be the outputs?
  a) 80 actions (a number in the range 0-79) : that is 4 possible actions for one of 20 possible players
     - 0-3   = player1 (up, right, down, left)
     - 4-7   = player2 (up, right, down, left)
     - 8-11  = player3 (up, right, down, left)
     - 12-15 = player4 (up, right, down, left)
     - 16-19 = player5 (up, right, down, left)
     ...
     - 76-79 = player20 (up, right, down, left)

     where players are ordered from left to right, top to bottom on the board

--------------------------------------
--- Approach to training the brain ---
--------------------------------------

Experiment #1: Train the brain to select a player unit that exists using 1 input - different ranges
---------------------------------------------------------------------------------------------------
a) Using 1 input in the range 1-20:
    - 1 input in the range 1-20 to represent the number of player units
    - 80 outputs
    - reward brain for outputting an action for a an existing player
    - punish brain for outputting an action for a non existing player
    - track reward
    - reward going consistently up indicates the brain as learned to select an existing player

    eg. For an input of 3,
        - reward +1 to the brain for an output in the range 0-11
        - reward -2 to the brain for an output in the range 12-79

b) Using 1 input in the range 1-10:
    - same as a) except with a reduced input range
    - 40 outputs

c) Using 1 input in the range 1-5:
    - same as b) except with a reduced input range
    - 20 outputs

d) Using 1 input in the range 1-2:
    - same as c) except with a reduced input range
    - 8 outputs


Experiment #2: Train the brain to select a player unit that exists using 1 input - values 1-2
---------------------------------------------------------------------------------------------
Using 1 input in the range 1-2:
    - 1 input in the range 1-2 to represent the number of player units
    - 8 outputs
    - keep training until average reward is > 0.9


Experiment #3: Train the brain to select a player unit that exists using 81 inputs - values 0-1
------------------------------------------------------------------
a) Using 81 inputs of values 0 or 1:
    - same as a) except using 81 inputs for board state with values...
         - 0 = empty square
         - 1 = player

    eg. For an input of 1,1,1,0,0,0,......0
        - reward +1 to the brain for an output in the range 0-11
        - reward -2 to the brain for an output in the range 12-79

Outcome:
- Having 81 inputs takes about 16 seconds per iterations (really slow!)
- ETA for 160,000 iterations is 106 minutes


Experiment #4: Graph Number of Inputs vs Learning Time (for 8000 iterations)
------------------------------------------------------------------
Purpose:
  Determine how the number of inputs used effects the learning time

Result
- Having 8 inputs takes about 67 mins to do 160,000 iterations
- Having 16 inputs takes about 69 mins to do 160,000 iterations


Experiment #5: Train with 9 inputs
----------------------------------
- each input represents 9 board square states which have been binary encoded into 36 bits (9 x 4 bits)

According to this article the maximum integer which can be represented in javascript is Math.pow(2, 53)
http://www.2ality.com/2012/04/number-encoding.html



Experiment #6: Train the brain to select a player unit that exists using 81 inputs - values 0-1
------------------------------------------------------------------
a) Using 81 inputs of values 0 or 1:
    - same as a) except using 81 inputs for board state with values...
         - 0 = empty square
         - 1 = player

    eg. For an input of 1,1,1,0,0,0,......0
        - reward +1 to the brain for an output in the range 0-11
        - reward -2 to the brain for an output in the range 12-79


Experiment #7: Train the brain to select a player unit that exists using 81 inputs - values 0-5
-----------------------------------------------------------------------------------------------
a) Using 81 inputs of values 0-5:
    - same as a) except using 81 inputs for board state with values...
         - 0 = empty square
         - 1-5 = player state (1=player not moving, 2=player moving up, 3=player moving right, 4=player moving down, 5=player moving left)

    eg. For an input of 1,2,3,0,0,0,......0
        - reward +1 to the brain for an output in the range 0-11
        - reward -2 to the brain for an output in the range 12-79


Experiment #8: Train the brain to select a player move that exists
------------------------------------------------------------------
    - 81 inputs for board state with values...
         - 0 = empty square
         - 1-5 = player state
             - 1 = not moving
             - 2 = moving up
             - 3 = moving right
             - 4 = moving down
             - 5 = moving left
    - 1 output in the range 0-79
      - 0-3   = player1 (up, right, down, left)
      - 4-7   = player2 (up, right, down, left)
      - 8-11  = player3 (up, right, down, left)
      - 12-79 = player4 .... player20
    - reward brain for outputting an action for a an existing player
    - reward brain for outputting an available player move
    - punish brain for outputting an action for a non existing player
    - punish brain for outputting a non-available player move
    - track reward
    - reward going consistently up indicates the brain as learned to select an existing player

    eg. For an input of 1,2,3,0,0,0,......0
        Note: This represents
            - player1: not moving
            - player2: moving up
            - player3: moving right
            - no other players
        - reward +1 to the brain for an output in the range 0-11
        - reward +1 to the brain for an output of either 0-3, 5-8, 10-11
        - reward -2 to the brain for an output in the range 12-79
        - reward -2 to the brain for an output of either 4 or 9

----------------------
*** Decisions Made ***
----------------------

Game State should be determined from javascript game internals
- For training purposes I'll need to read the game state from the game internals to improve training times
- Once the brain is fully trained and performance is not an issue, game state could be read
  from the DOM so that the AI bot can executed as a bookmarklet on the actual Math Effect website

Number of inputs to the brain
- Found that the more inputs to the brain, the longer it takes to train
- Instead of 81 inputs, reduced to 9 inputs using binary encoding


-------------
*** Tasks ***
-------------

- Alter Math Effect so that when training the UI is not updated, otherwise its too slow!
- Read game state from the game internals when training the brain

- Prepare video presentation

